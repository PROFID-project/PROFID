##############################################################################
# PROFID — Study 5
# Script 08: Between-database variation + GEO trend model
#
# Input: df_study5_hfref.rds (from Script 1)
# Cohort: HFrEF only (LVEF <40%) — expected to be restricted by Script 1
##############################################################################
options(stringsAsFactors = FALSE)
suppressPackageStartupMessages({
  library(dplyr)
  library(tidyr)
  library(readr)
  library(ggplot2)
  library(broom)
  library(splines)
  library(forcats)
  library(tibble)
})
log_line <- function(...) cat(format(Sys.time(), "%Y-%m-%d %H:%M:%S"), "|", ..., "\n")
# =============================================================================
# 0) Paths
# =============================================================================
BASE_DIR <- "T:/Study_5"

OUT_DIR <- file.path(BASE_DIR, "Results_Study5", "Script8_DB_variation_GEO")
dir.create(OUT_DIR, recursive = TRUE, showWarnings = FALSE)

input_candidates <- c(
  file.path(BASE_DIR, "Results_Study5", "Script1_HFrEF_UPDATED", "df_study5_hfref.rds"),
  file.path(BASE_DIR, "df_study5_hfref.rds"),
  file.path(BASE_DIR, "df_study5.rds"),
  file.path("S:/AG/f-dhzc-profid/Data Transfer to Charite", "df_study5.rds")
)
IN_FILE <- input_candidates[file.exists(input_candidates)][1]
if (is.na(IN_FILE)) stop("[ERROR] No input dataset found. Checked:\n", paste(input_candidates, collapse = "\n"))

log_line("[INFO] Input:", IN_FILE)
log_line("[INFO] Output dir:", OUT_DIR)
# =============================================================================
# 1) Load
# =============================================================================
dat <- readRDS(IN_FILE)
if (!is.data.frame(dat)) stop("[ERROR] Loaded object is not a data.frame.")
log_line("[INFO] Loaded. n=", nrow(dat), " p=", ncol(dat))

# =============================================================================
# 2) Minimal harmonisation
# =============================================================================
must_have_any <- function(x, candidates) any(candidates %in% names(x))
pick_first <- function(x, candidates) candidates[candidates %in% names(x)][1]

to01 <- function(x) {
  if (is.logical(x)) return(as.integer(x))
  if (is.numeric(x)) return(ifelse(is.na(x), NA_integer_, as.integer(x != 0)))
  xx <- tolower(trimws(as.character(x)))
  out <- rep(NA_integer_, length(xx))
  out[xx %in% c("1","yes","y","true","t")] <- 1L
  out[xx %in% c("0","no","n","false","f")] <- 0L
  out
}

# Year_index
if (!("Year_index" %in% names(dat))) {
  y <- pick_first(dat, c("Year", "year", "IndexYear", "index_year", "indexyear"))
  if (!is.na(y)) dat$Year_index <- suppressWarnings(as.integer(dat[[y]]))
}
dat$Year_index <- suppressWarnings(as.integer(dat$Year_index))

# DB
if (!("DB" %in% names(dat))) dat$DB <- "ALL"
dat$DB <- factor(dat$DB)

# Therapy vars must exist
if (!must_have_any(dat, c("RAAS","BB","MRA"))) {
  stop("[ERROR] Missing therapy vars (RAAS/BB/MRA). we likely did not load df_study5_hfref.rds.")
}

dat <- dat %>%
  mutate(
    RAAS = to01(RAAS),
    BB = to01(BB),
    MRA = to01(MRA),
    Diuretics = if ("Diuretics" %in% names(.)) to01(Diuretics) else NA_integer_
  )

# HF_n_classes
if (!("HF_n_classes" %in% names(dat))) {
  if ("HF_GDMT_count4" %in% names(dat)) dat$HF_n_classes <- suppressWarnings(as.integer(dat$HF_GDMT_count4))
}
dat$HF_n_classes <- suppressWarnings(as.integer(dat$HF_n_classes))

# Primary outcome
if (!("HF_BIN_eq3" %in% names(dat))) {
  dat$HF_BIN_eq3 <- ifelse(is.na(dat$HF_n_classes), NA_integer_, as.integer(dat$HF_n_classes == 3))
}

# Optional covariates
if (!("Age_num" %in% names(dat)) && ("Age" %in% names(dat))) dat$Age_num <- suppressWarnings(as.numeric(dat$Age))
if ("Age_num" %in% names(dat)) dat$Age_num <- suppressWarnings(as.numeric(dat$Age_num))

if (!("Sex_BIN_Male" %in% names(dat))) {
  s <- pick_first(dat, c("Sex", "sex", "male", "Male"))
  if (!is.na(s)) dat$Sex_BIN_Male <- to01(dat[[s]])
}
if ("Sex_BIN_Male" %in% names(dat)) dat$Sex_BIN_Male <- to01(dat$Sex_BIN_Male)

if (!("eGFR_log1p" %in% names(dat)) && ("eGFR_num" %in% names(dat))) {
  dat$eGFR_log1p <- log1p(pmax(suppressWarnings(as.numeric(dat$eGFR_num)), 0))
}
# =============================================================================
# 3) AUDIT table
# =============================================================================
audit <- tibble(
  metric = c("n_rows","n_DB","year_min","year_max","HF_BIN_eq3_nonmiss","HF_BIN_eq3_events"),
  value = c(
    nrow(dat),
    dplyr::n_distinct(dat$DB),
    suppressWarnings(min(dat$Year_index, na.rm = TRUE)),
    suppressWarnings(max(dat$Year_index, na.rm = TRUE)),
    sum(!is.na(dat$HF_BIN_eq3)),
    sum(dat$HF_BIN_eq3 == 1, na.rm = TRUE)
  )
)
write_csv(audit, file.path(OUT_DIR, "AUDIT_basic.csv"))
log_line("[OK] Saved AUDIT_basic.csv")

# =============================================================================
# 4) Observed variation by DB (rates + Wilson CI)
# =============================================================================
wilson_ci <- function(x, n, conf = 0.95) {
  if (n == 0) return(c(NA_real_, NA_real_))
  z <- qnorm(1 - (1 - conf)/2)
  p <- x / n
  den <- 1 + z^2/n
  center <- (p + z^2/(2*n)) / den
  half <- (z * sqrt((p*(1-p) + z^2/(4*n))/n)) / den
  c(center - half, center + half)
}

db_rate <- function(data, outcome, min_n = 50) {
  stopifnot(outcome %in% names(data))
  tmp <- data %>%
    filter(!is.na(.data[[outcome]]), !is.na(DB)) %>%
    group_by(DB) %>%
    summarise(
      n = n(),
      events = sum(.data[[outcome]] == 1),
      rate = events / n,
      .groups = "drop"
    ) %>%
    filter(n >= min_n)
  
  if (nrow(tmp) == 0) return(tmp)
  
  ci <- t(mapply(wilson_ci, tmp$events, tmp$n))
  tmp$low <- ci[,1]
  tmp$high <- ci[,2]
  tmp
}

plot_db_rates <- function(tab, outcome_name) {
  ggplot(tab, aes(x = fct_reorder(DB, rate), y = rate)) +
    geom_point() +
    geom_errorbar(aes(ymin = low, ymax = high), width = 0.2) +
    coord_flip() +
    labs(x = "Database (DB)", y = "Observed proportion",
         title = paste0("Observed DB variation: ", outcome_name))
}

outcomes <- c("HF_BIN_eq3","RAAS","BB","MRA","Diuretics")
outcomes <- outcomes[outcomes %in% names(dat)]

for (outc in outcomes) {
  tab <- db_rate(dat, outc, min_n = 50)
  write_csv(tab, file.path(OUT_DIR, paste0("DB_observed_rates_", outc, ".csv")))
  if (nrow(tab) > 0) {
    p <- plot_db_rates(tab, outc)
    ggsave(file.path(OUT_DIR, paste0("DB_observed_rates_", outc, ".png")),
           p, width = 10, height = 6, dpi = 220)
    log_line("[OK] Observed DB rates:", outc)
  } else {
    log_line("[SKIP] Observed DB rates (no DB with n>=50):", outc)
  }
}

# =============================================================================
# 5) GEO trend model (logistic)
# outcome ~ ns(Year_index, df=4) + DB (+ optional covariates)
# =============================================================================
#  thresholds for separation control
MIN_EV_DEFAULT <- 5L
MIN_NONEV_DEFAULT <- 5L
MIN_EV_BY_OUTCOME <- c(HF_BIN_eq3 = 10L, MRA = 10L)
MIN_NONEV_BY_OUTCOME <- c(HF_BIN_eq3 = 10L, MRA = 10L)

filter_db_extremes <- function(d, outcome, out_dir) {
  min_ev <- if (outcome %in% names(MIN_EV_BY_OUTCOME)) MIN_EV_BY_OUTCOME[[outcome]] else MIN_EV_DEFAULT
  min_nonev <- if (outcome %in% names(MIN_NONEV_BY_OUTCOME)) MIN_NONEV_BY_OUTCOME[[outcome]] else MIN_NONEV_DEFAULT
  
  cnt <- d %>%
    group_by(DB) %>%
    summarise(
      n = n(),
      events = sum(.data[[outcome]] == 1, na.rm = TRUE),
      nonevents= sum(.data[[outcome]] == 0, na.rm = TRUE),
      .groups = "drop"
    )
  
  write_csv(cnt, file.path(out_dir, paste0("GEO_DB_outcome_counts_", outcome, ".csv")))
  
  keep_db <- cnt %>%
    filter(events >= min_ev, nonevents >= min_nonev) %>%
    pull(DB) %>% as.character()
  
  dropped <- setdiff(as.character(unique(d$DB)), keep_db)
  if (length(dropped) > 0) {
    write_csv(
      tibble(DB = dropped, outcome = outcome, min_events = min_ev, min_nonevents = min_nonev),
      file.path(out_dir, paste0("GEO_DB_dropped_", outcome, ".csv"))
    )
    log_line("[INFO] GEO:", outcome, "dropped DBs due to low events/nonevents:", paste(dropped, collapse = ", "))
  }
  
  d %>%
    filter(as.character(DB) %in% keep_db) %>%
    mutate(DB = droplevels(factor(DB)))
}

drop_single_level_terms <- function(d, vars) {
  keep <- c()
  for (v in vars) {
    if (!(v %in% names(d))) next
    x <- d[[v]]
    if (is.factor(x)) {
      if (nlevels(droplevels(x)) >= 2) keep <- c(keep, v)
    } else {
      uu <- unique(x[!is.na(x)])
      if (length(uu) >= 2) keep <- c(keep, v)
    }
  }
  keep
}

# ONE function used for BOTH: model fit and predictions (same filtering)
prepare_geo_data <- function(data, outcome) {
  if (!(outcome %in% names(data))) return(NULL)
  
  d <- data %>%
    filter(!is.na(.data[[outcome]]), !is.na(Year_index), !is.na(DB)) %>%
    mutate(DB = droplevels(factor(DB)))
  
  if (nrow(d) < 200) return(NULL)
  
  d <- filter_db_extremes(d, outcome, OUT_DIR)
  if (nrow(d) < 200) return(NULL)
  
  # If DB drops to a single level, we still allow fitting (without DB term)
  d
}

fit_geo <- function(data, outcome) {
  d <- prepare_geo_data(data, outcome)
  if (is.null(d)) return(NULL)
  
  base_terms <- c("splines::ns(Year_index, df=4)")
  opt_terms <- c()
  if ("Age_num" %in% names(d)) opt_terms <- c(opt_terms, "Age_num")
  if ("Sex_BIN_Male" %in% names(d)) opt_terms <- c(opt_terms, "Sex_BIN_Male")
  if ("eGFR_log1p" %in% names(d)) opt_terms <- c(opt_terms, "eGFR_log1p")
  opt_terms <- drop_single_level_terms(d, opt_terms)
  
  terms <- base_terms
  if (nlevels(d$DB) >= 2) {
    terms <- c(terms, "DB")
  } else {
    log_line("[WARN] GEO:", outcome, "-> DB has <2 levels after filtering; fitting without DB.")
  }
  terms <- c(terms, opt_terms)
  
  fml <- as.formula(paste0(outcome, " ~ ", paste(terms, collapse = " + ")))
  glm(fml, data = d, family = binomial())
}

export_or_table <- function(fit, out_path) {
  tt <- broom::tidy(fit, conf.int = TRUE, exponentiate = TRUE)
  write_csv(tt, out_path)
  tt
}

plot_db_or <- function(or_tbl, outcome) {
  db_tbl <- or_tbl %>%
    filter(grepl("^DB", term)) %>%
    mutate(DB = sub("^DB", "", term)) %>%
    filter(is.finite(estimate), is.finite(conf.low), is.finite(conf.high)) %>%
    arrange(estimate)
  
  if (nrow(db_tbl) == 0) return(NULL)
  
  ggplot(db_tbl, aes(x = estimate, y = fct_inorder(DB))) +
    geom_point() +
    geom_errorbar(aes(xmin = conf.low, xmax = conf.high), height = 0.2, orientation = "y") +
    geom_vline(xintercept = 1, linetype = 2) +
    scale_x_log10() +
    labs(x = "Adjusted OR (log scale; vs reference DB)", y = "DB",
         title = paste0("Adjusted DB ORs: ", outcome))
}

predict_trend_over_years <- function(fit, d_used, outcome) {
  if (is.null(d_used) || nrow(d_used) == 0) return(NULL)
  
  yrs <- sort(unique(d_used$Year_index))
  yrs <- yrs[is.finite(yrs)]
  yrs <- yrs[yrs >= 2000 & yrs <= 2020]
  if (length(yrs) == 0) return(NULL)
  
  db_levels_fit <- NULL
  if (!is.null(fit$xlevels) && "DB" %in% names(fit$xlevels)) db_levels_fit <- fit$xlevels$DB
  
  mf <- model.frame(fit)
  
  if (!is.null(db_levels_fit)) {
    grid <- expand.grid(Year_index = yrs, DB = db_levels_fit, KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE)
    grid$DB <- factor(grid$DB, levels = db_levels_fit)
  } else {
    grid <- data.frame(Year_index = yrs)
  }
  
  if ("Age_num" %in% names(mf)) grid$Age_num <- median(d_used$Age_num, na.rm = TRUE)
  if ("Sex_BIN_Male" %in% names(mf)) grid$Sex_BIN_Male <- round(mean(d_used$Sex_BIN_Male, na.rm = TRUE))
  if ("eGFR_log1p" %in% names(mf)) grid$eGFR_log1p <- median(d_used$eGFR_log1p, na.rm = TRUE)
  
  grid$pred <- suppressWarnings(predict(fit, newdata = grid, type = "response"))
  
  if (!is.null(db_levels_fit)) {
    wtab <- prop.table(table(d_used$DB))
    grid$w <- as.numeric(wtab[as.character(grid$DB)])
    out <- as_tibble(grid) %>%
      group_by(Year_index) %>%
      summarise(pred = weighted.mean(pred, w, na.rm = TRUE), .groups = "drop")
  } else {
    out <- as_tibble(grid) %>% transmute(Year_index, pred)
  }
  
  out$outcome <- outcome
  out
}

for (outc in outcomes) {
  fit <- fit_geo(dat, outc)
  if (is.null(fit)) {
    log_line("[SKIP] GEO model (too small / degenerate after filtering):", outc)
    next
  }
  
  or_tbl <- export_or_table(fit, file.path(OUT_DIR, paste0("GEO_model_OR_", outc, ".csv")))
  
  p_or <- plot_db_or(or_tbl, outc)
  if (!is.null(p_or)) {
    ggsave(file.path(OUT_DIR, paste0("GEO_DB_OR_forest_", outc, ".png")),
           p_or, width = 10, height = 6, dpi = 220)
  } else {
    log_line("[INFO] No usable DB OR plot:", outc)
  }
  
  d_used <- prepare_geo_data(dat, outc)
  tr <- predict_trend_over_years(fit, d_used, outc)
  if (!is.null(tr)) {
    write_csv(tr, file.path(OUT_DIR, paste0("GEO_pred_trends_overall_", outc, ".csv")))
    p_tr <- ggplot(tr, aes(x = Year_index, y = pred)) +
      geom_line() +
      labs(x = "Year", y = "Predicted probability (DB-marginal)",
           title = paste0("Adjusted temporal trend: ", outc))
    ggsave(file.path(OUT_DIR, paste0("GEO_pred_trends_overall_", outc, ".png")),
           p_tr, width = 10, height = 5.5, dpi = 220)
  }
  
  saveRDS(fit, file.path(OUT_DIR, paste0("GEO_model_", outc, ".rds")))
  log_line("[OK] GEO model + outputs:", outc)
}
# =============================================================================
# 6)  ML variable importance
# =============================================================================
HAS_RANGER <- requireNamespace("ranger", quietly = TRUE)
HAS_XGBOOST <- requireNamespace("xgboost", quietly = TRUE)

make_ml_design <- function(data, outcome) {
  if (!(outcome %in% names(data))) return(NULL)
  
  keep <- intersect(
    c("Year_index","DB","Age_num","Sex_BIN_Male","eGFR_log1p",
      "Diabetes_BIN_Yes","Hypertension_BIN_Yes","Smoking_BIN_Yes",
      "AF_atrial_flutter_BIN_Yes","Stroke_TIA_BIN_Yes","PCI_BIN_Yes","CABG_BIN_Yes"),
    names(data)
  )
  if (length(keep) < 2) return(NULL
                               
  )
  
  d <- data %>%
    select(all_of(c(outcome, keep))) %>%
    filter(!is.na(.data[[outcome]]))
  
  if (nrow(d) < 200) return(NULL)
  
  y <- as.integer(d[[outcome]])
  x_df <- d[, keep, drop = FALSE]
  
  all_na <- sapply(x_df, function(v) all(is.na(v)))
  if (any(all_na)) x_df <- x_df[, !all_na, drop = FALSE]
  if (ncol(x_df) == 0) return(NULL)
  
  cc <- complete.cases(x_df)
  x_df <- x_df[cc, , drop = FALSE]
  y <- y[cc]
  if (length(y) < 200) return(NULL)
  
  mm <- model.matrix(~ . , data = x_df)
  if ("(Intercept)" %in% colnames(mm)) mm <- mm[, colnames(mm) != "(Intercept)", drop = FALSE]
  if (ncol(mm) == 0) return(NULL)
  
  zv <- apply(mm, 2, function(v) {
    s <- stats::sd(v, na.rm = TRUE)
    is.finite(s) && isTRUE(all.equal(s, 0))
  })
  if (any(zv)) mm <- mm[, !zv, drop = FALSE]
  if (ncol(mm) == 0) return(NULL)
  
  list(y = y, X = mm)
}

run_ml_importance <- function(data, outcome) {
  ml <- make_ml_design(data, outcome)
  if (is.null(ml)) {
    log_line("[INFO] ML skipped (insufficient design matrix):", outcome)
    return(invisible(NULL))
  }
  
  if (HAS_RANGER) {
    dat_rf <- data.frame(y = factor(ml$y, levels = c(0,1)), as.data.frame(ml$X))
    rf <- ranger::ranger(y ~ ., data = dat_rf, importance = "permutation", num.trees = 500)
    imp <- sort(rf$variable.importance, decreasing = TRUE)
    imp_df <- tibble(term = names(imp), importance = as.numeric(imp))
    write_csv(imp_df, file.path(OUT_DIR, paste0("ML_RF_varimp_", outcome, ".csv")))
    
    p <- ggplot(head(imp_df, 25), aes(x = importance, y = forcats::fct_reorder(term, importance))) +
      geom_col() +
      labs(x = "Permutation importance", y = "Predictor",
           title = paste0("RF variable importance: ", outcome))
    ggsave(file.path(OUT_DIR, paste0("ML_RF_varimp_", outcome, ".png")),
           p, width = 10, height = 7, dpi = 220)
    log_line("[OK] RF varimp:", outcome)
  } else {
    log_line("[INFO] ranger not installed -> skipping RF varimp.")
  }
  
  if (HAS_XGBOOST) {
    dtrain <- xgboost::xgb.DMatrix(data = ml$X, label = ml$y)
    params <- list(
      objective = "binary:logistic",
      eval_metric = "logloss",
      max_depth = 3,
      eta = 0.1,
      subsample = 0.8,
      colsample_bytree = 0.8
    )
    xgb <- xgboost::xgb.train(params = params, data = dtrain, nrounds = 200, verbose = 0)
    imp <- xgboost::xgb.importance(model = xgb)
    write_csv(imp, file.path(OUT_DIR, paste0("ML_XGB_gain_", outcome, ".csv")))
    
    p <- ggplot(head(imp, 25), aes(x = Gain, y = forcats::fct_reorder(Feature, Gain))) +
      geom_col() +
      labs(x = "Gain", y = "Feature",
           title = paste0("XGBoost importance (Gain): ", outcome))
    ggsave(file.path(OUT_DIR, paste0("ML_XGB_gain_", outcome, ".png")),
           p, width = 10, height = 7, dpi = 220)
    log_line("[OK] XGB varimp:", outcome)
  } else {
    log_line("[INFO] xgboost not installed -> skipping XGB varimp.")
  }
}

# run ML on primary endpoint 
run_ml_importance(dat, "HF_BIN_eq3")

log_line("[DONE] Script 08 completed.")

